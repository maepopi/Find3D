Metadata-Version: 2.4
Name: find3d
Version: 0.1.0
Summary: Find Any Part in 3D - ICCV 2025
Author: Ziqi Ma
License-Expression: Apache-2.0
Requires-Python: <3.11,>=3.10
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: torch>=2.7.0
Requires-Dist: torchvision>=0.18.0
Requires-Dist: torchmetrics>=0.10.3
Requires-Dist: torch-geometric>=2.4.0
Requires-Dist: xformers>=0.0.27
Requires-Dist: spconv-cu12>=2.3.0
Requires-Dist: omegaconf>=2.3.0
Requires-Dist: iopath>=0.1.10
Requires-Dist: h5py>=3.8.0
Requires-Dist: pyyaml>=6.0.0
Requires-Dist: sharedarray>=3.2.3
Requires-Dist: tensorboard>=2.14.0
Requires-Dist: tensorboardX>=2.6.2
Requires-Dist: yapf>=0.32.0
Requires-Dist: addict>=2.4.0
Requires-Dist: einops>=0.7.0
Requires-Dist: scipy>=1.10.0
Requires-Dist: plyfile>=1.0.0
Requires-Dist: termcolor>=2.3.0
Requires-Dist: timm>=0.9.0
Requires-Dist: transformers>=4.34.0
Requires-Dist: open3d>=0.17.0
Requires-Dist: sentencepiece>=0.2.0
Requires-Dist: requests>=2.30.0
Requires-Dist: pillow>=10.0.0
Requires-Dist: numpy>=1.24.0
Requires-Dist: gradio>=4.0.0
Provides-Extra: dev
Requires-Dist: pytest>=7.0; extra == "dev"
Requires-Dist: black>=23.0; extra == "dev"
Requires-Dist: isort>=5.12.0; extra == "dev"
Dynamic: license-file

# Find3D: Find Any Part in 3D
### ICCV 2025 Highlightâœ¨

> **âš ï¸ DISCLAIMER:** This enhanced version was created with assistance from Claude AI (GitHub Copilot). The original Find3D model and research remain the work of [Ziqi Ma](https://ziqi-ma.github.io/), [Yisong Yue](http://www.yisongyue.com/), and [Georgia Gkioxari](https://gkioxari.github.io/). Claude enhancements are documented in the "What's New" section below.

**Find3D: training a model to segment _any_ part in _any_ object based on _any_ text query using 3D assets from the internet**

[Ziqi Ma][zm], [Yisong Yue][yy], [Georgia Gkioxari][gg]

[[`Project Page`](https://ziqi-ma.github.io/find3dsite/)] [[`arXiv`](https://arxiv.org/abs/2411.13550)] [[`Gradio Demo`](https://huggingface.co/spaces/ziqima/Find3D)]

![teaser](media/teaser.png?raw=true)

---

## ğŸ†• What's New (Claude Enhancements)

This fork adds comprehensive tooling and interfaces to make Find3D easier to use:

### New Features Added
- âœ… **3D to Point Cloud Converter** (`convert_3d_to_pcd.py`)
  - Convert any 3D format (.obj, .glb, .ply, .stl, .off, .gltf, .fbx) to point clouds
  - Multiple point sampling algorithms (Poisson disk, random)
  - Flexible coloring options (height-based, random, vertex-based)
  - Batch processing support
  - Command-line tool + Python API

- âœ… **Gradio Web Interface** (`gradio_app.py`)
  - Interactive two-tab interface (Converter + Inference)
  - Upload 3D models or point clouds
  - Configure all parameters visually
  - Real-time inference with Find3D
  - Browser-based visualization

- âœ… **Example Models** (`generate_example_models.py`)
  - Test shapes: cube, sphere, pyramid, torus
  - Pre-converted to point clouds for immediate testing

- âœ… **Comprehensive Testing**
  - `test_gradio_setup.py` - Verify Gradio interface (5 tests)
  - `test_converter_setup.py` - Verify converter tools (7 tests)
  - All tests passing âœ…

- âœ… **Complete Documentation**
  - 3D_CONVERTER_GUIDE.md - Converter reference
  - CONVERTER_QUICKSTART.md - Quick-start examples
  - GRADIO_GUIDE.md - Interface guide
  - INSTALLATION.md - Setup instructions
  - Plus this comprehensive README

### Framework Versions
- **PyTorch**: 2.10.0+cu128 (> 2.7 requirement met)
- **torch-geometric**: 2.7.0
- **Gradio**: 6.5.1
- **Python**: 3.10.19
- **CUDA**: 12.8

### Compatibility Fixes
- âœ… Updated for PyTorch > 2.7
- âœ… Torch-scatter compatibility shim
- âœ… Flash-attention optional (graceful fallback)
- âœ… Gradio 6.5.1 API compatibility

---

## ğŸ“‹ Table of Contents

1. [Quick Start](#quick-start)
2. [Installation](#installation)
3. [Using the Converter](#using-the-converter)
4. [Using the Gradio Interface](#using-the-gradio-interface)
5. [Original Find3D Features](#original-find3d)
6. [Dataset](#dataset)
7. [Data Engine](#dataengine)
8. [Inference on Benchmarks](#infbench)
9. [Inference in the Wild](#infwild)
10. [Training](#training)
11. [Citing](#citing)

---

## ğŸš€ Quick Start <a name="quick-start"></a>

### Launch the Web Interface (Using uv - Easiest!)

```bash
cd /path/to/Find3D
uv run find3d
```

Or directly with Python:
```bash
uv run python gradio_app.py
```

Then open: **http://localhost:7860**

### Launch with Traditional Methods

**Using conda/venv environment:**
```bash
cd /path/to/Find3D
source .venv/bin/activate  # or: conda activate find3d
python gradio_app.py
```

**Two tabs available:**
1. **ğŸ”„ Converter**: Upload 3D models â†’ Download point clouds
2. **ğŸ§  Inference**: Run Find3D queries on point clouds

### Using Example Models

```bash
# Generate test shapes
python generate_example_models.py

# See converted examples
ls converted/*.pcd

# Launch interface
uv run find3d
```

**Try this workflow:**
1. Converter tab: Upload `example_models/cube.obj`
2. Configure: 10,000 points, Poisson sampling, height coloring
3. Download converted file
4. Inference tab: Upload the .pcd file
5. Query: "upper face, lower face, side"
6. See segmentation results!

---

## ğŸ”§ Installation <a name="installation"></a>

### Prerequisites
- Python 3.8+
- CUDA 11.8+ (for GPU support)
- ~20GB free disk space

### Option 1: Using uv (Modern Package Manager) - **Recommended**

```bash
# Install uv
curl -LsSf https://astral.sh/uv/install.sh | sh

# Create environment
cd Find3D
uv venv .venv
source .venv/bin/activate

# Install dependencies
pip install torch==2.10.0 --index-url https://download.pytorch.org/whl/cu128
pip install -r model/requirements.txt
pip install gradio>=6.0.0

# Optional: for advanced converter features
pip install trimesh
```

### Option 2: Using conda (Traditional)

```bash
cd model
conda create -n find3d python=3.10
conda activate find3d
pip install torch==2.10.0 --index-url https://download.pytorch.org/whl/cu128
pip install -r requirements.txt
cd ..
pip install gradio>=6.0.0
```

### Verify Installation

```bash
# Check all components work
python test_gradio_setup.py
python test_converter_setup.py

# Both should show: âœ… ALL TESTS PASSED

# Quick launch test (using uv)
uv run find3d
```

### Optional: Build Pointcept from Source

```bash
git clone https://github.com/Pointcept/Pointcept.git
cd Pointcept/libs/pointops
python setup.py install
cd ../../../
```

### Optional: Build FlashAttention from Source

```bash
git clone https://github.com/Dao-AILab/flash-attention.git
cd flash-attention
MAX_JOBS=4 python setup.py install
cd ..
```

> Note: Model works without these optional packages (with graceful fallbacks).

---

## ğŸ”„ Using the Converter <a name="using-the-converter"></a>

### Web Interface (Recommended)

1. Launch: `python gradio_app.py`
2. Go to "ğŸ”„ 3D â†’ Point Cloud Converter" tab
3. Upload your 3D model
4. Configure:
   - **Points to Sample**: 10K-20K typical (more = higher detail)
   - **Sampling Method**: Poisson (uniform) or Random (fast)
   - **Coloring**: Height, Random, or Vertex-based
5. Click "Convert"
6. Download `.pcd` file

### Command Line

```bash
# Single file conversion
python convert_3d_to_pcd.py model.obj

# Custom settings
python convert_3d_to_pcd.py model.glb \
  -o output.pcd \
  -n 30000 \
  -m poisson \
  -c height

# Batch convert directory
python convert_3d_to_pcd.py --batch ./models/ --output ./pcds/

# With visualization
python convert_3d_to_pcd.py model.ply --visualize

# Help
python convert_3d_to_pcd.py --help
```

### Python API

```python
from convert_3d_to_pcd import convert_3d_to_pcd, batch_convert

# Single file
output_path = convert_3d_to_pcd(
    input_file="chair.glb",
    output_file="chair.pcd",
    num_points=20000,
    sampling_method="poisson",
    color_method="height"
)

# Batch process
files = batch_convert(
    input_dir="./models/",
    output_dir="./pcds/",
    num_points=15000
)
```

### Supported Formats

**Input**: .obj, .glb, .ply, .stl, .off, .gltf, .fbx, and more
**Output**: .pcd (Open3D Point Cloud Data format)

### Coloring Methods

| Method | Visual | Best For |
|--------|--------|----------|
| **height** | Blue (bottom) â†’ Red (top) | Understanding orientation |
| **random** | Colorful variation | Visual interest |
| **vertex** | Original mesh colors | Preserving meaningful colors |

---

## ğŸ§  Using the Gradio Interface <a name="using-the-gradio-interface"></a>

### Launch

```bash
python gradio_app.py
```

Opens at: **http://localhost:7860**

### Converter Tab: ğŸ”„ 3D â†’ Point Cloud Converter

**Purpose**: Convert 3D models to point clouds

1. **Upload 3D Model**
   - Drag and drop any supported format
   - Or click to browse

2. **Configure**
   - **Points to Sample** (1K-100K): Higher = more detail
   - **Sampling Method**: 
     - Poisson (recommended) - uniform distribution
     - Random - faster but less uniform
   - **Coloring**:
     - Height - z-axis gradient
     - Random - random colors
     - Vertex - use original colors

3. **Convert** and download .pcd file

### Inference Tab: ğŸ§  Inference

**Purpose**: Run Find3D to find parts using text queries

1. **Input Selection**
   - Check "Use Sample Point Cloud" for built-in test data
   - Uncheck to upload your own .pcd file

2. **Text Queries**
   - Enter comma-separated part names
   - Examples: "handle, blade" or "wheel, frame, door"
   - Be specific for best results

3. **Advanced Options**
   - **Output Mode**:
     - Segmentation: Hard assignment to classes
     - Heatmap: Confidence scores per query
   - **Temperature** (0.1-2.0):
     - Low = sharp boundaries
     - High = soft boundaries
   - **Random Seed**: For reproducibility

4. **Run Inference**
   - Click "ğŸš€ Run Inference"
   - View results in Output, Analysis, or Raw JSON tabs

---

## Original Find3D <a name="original-find3d"></a>

### Overview

Find3D consists of a data engine which automatically annotates training data and an open-world 3D part segmentation model trained on diverse objects provided by the data engine. We share code both for the data engine and the model.

Scripts for various steps of the data engine are explained in [`dataengine/README.md`](dataengine/README.md). Below we demonstrate how to perform inference both on benchmarks and on user-provided point cloud files with Find3D. We also provide the command to train Find3D from scratch.

---

## Environment Setup <a name="environment"></a>

### Model Environment

The Find3D model requires:
- GPU with CUDA support
- PyTorch 2.0+
- Python 3.8+

**Installation:**

```bash
cd model
conda create -n find3d python=3.10
conda activate find3d
pip install -r requirements.txt
```

### Optional: Build Pointcept

```bash
git clone https://github.com/Pointcept/Pointcept.git
cd Pointcept/libs/pointops
python setup.py install
cd ../../..
```

### Optional: Build FlashAttention

```bash
git clone https://github.com/Dao-AILab/flash-attention.git
cd flash-attention
MAX_JOBS=4 python setup.py install
cd ..
```

> Building FlashAttention might take up to three hours.

---

## Dataset <a name="dataset"></a>

See [`model/evaluation/benchmark/README.md`](model/evaluation/benchmark/README.md) for instructions on downloading the benchmarks for evaluation.

Available benchmarks:
- ShapeNetPart
- PartNetE
- Objaverse-ShapeNetPart

---

## Data Engine <a name="dataengine"></a>

The environment setup for the data engine, as well as scripts for various steps, are detailed in [`dataengine/README.md`](dataengine/README.md).

The data engine automatically creates training data by:
- Downloading 3D assets
- Generating 2D renderings
- Creating semantic masks
- Annotating part labels
- Converting to point cloud format

---

## Inference on Benchmarks <a name="infbench"></a>

### Download Model

The trained model can be downloaded from HuggingFace:

```python
from transformers import AutoModel
model = AutoModel.from_pretrained("ziqima/find3d-checkpt0", dim_output=768)
```

### Run Benchmark Evaluation

Set up the environment:

```bash
cd model
export PYTHONPATH=[path to Find3D]
```

**Evaluation Options:**

- `--benchmark`: ShapeNetPart, PartNetE, or Objaverse
- `--data_root`: Path to benchmark data
- `--part_query`: Use "part" query instead of "part of object"
- `--use_shapenetpart_topk_prompt`: Use top-K prompts (PointCLIPV2 style)
- `--subset`: Evaluate on subset only
- `--canonical`: Use canonical orientation (no rotation)

**Example: Evaluate on ShapeNetPart**

```bash
python evaluation/benchmark/eval_benchmark.py \
  --benchmark ShapeNetPart \
  --data_root [path/to/data]
```

**Example: Evaluate on PartNetE**

```bash
python evaluation/benchmark/eval_benchmark.py \
  --benchmark PartNetE \
  --data_root [path/to/data]
```

**Example: Evaluate on Objaverse (Unseen)**

```bash
python evaluation/benchmark/eval_benchmark.py \
  --benchmark Objaverse \
  --data_root [path/to/data] \
  --objaverse_split unseen
```

---

## Inference in the Wild <a name="infwild"></a>

### Using the Gradio Interface (Recommended)

The easiest way to test on custom point clouds:

```bash
python gradio_app.py
```

Then use the **Inference** tab to upload any .pcd file and run queries.

### Using the Command-Line Script

Find3D can be evaluated on any point cloud (3D digital asset or 3D reconstruction):

```bash
cd model
export PYTHONPATH=[path to find3d]
```

**Two modes available:**

1. **Segmentation Mode** - Assign all query parts to point cloud

```bash
python evaluation/demo/eval_visualize.py \
  --object_path path/to/model.pcd \
  --mode segmentation \
  --queries "head" "ear" "arm" "leg" "body" "hand" "shoe"
```

2. **Heatmap Mode** - Get confidence heatmap for each query

```bash
python evaluation/demo/eval_visualize.py \
  --object_path path/to/model.pcd \
  --mode heatmap \
  --queries "hand" "shoe"
```

**Output:**
- Segmentation/heatmaps display in your browser as interactive Plotly visualizations
- Can be dragged and rotated for inspection
- Works with SSH remote visualization (opens in client browser)

---

## Training <a name="training"></a>

### Data Format

Find3D's data loader works with data formatted by the data engine. Each training object requires:

**Mask data directory:**
- `allmasks.pt` (n_masks Ã— 500 Ã— 500)
- `mask_labels.txt` (n_masks rows, each a label)
- `mask2pts.pt` (n_masks Ã— n_pts, binary mask-to-point mapping)
- `mask2view.pt` (n_masks, view IDs 0-9)

**Point data directory:**
- `normals.pt` (n_points Ã— 3)
- `points.pt` (n_points Ã— 3)
- `rgb.pt` (n_points Ã— 3)
- `point2face.pt` (point-to-face mapping)

See [`model/data/data.py`](model/data/data.py) for implementation details.

### Train from Scratch

```bash
python training/train.py \
  --ckpt_dir=[checkpoint_dir] \
  --lr=0.0003 \
  --eta_min=0.00005 \
  --batch_size=64 \
  --n_epoch=80 \
  --exp_suffix=[experiment_name]
```

### Training Parameters

- `--ckpt_dir`: Directory to save checkpoints
- `--lr`: Initial learning rate
- `--eta_min`: Minimum learning rate (for cosine annealing)
- `--batch_size`: Batch size
- `--n_epoch`: Number of epochs
- `--exp_suffix`: Experiment name suffix

---

## ğŸ§ª Testing

### Test Gradio Setup

```bash
python test_gradio_setup.py
```

Verifies:
- âœ“ Dependencies installed
- âœ“ CUDA available
- âœ“ Gradio working
- âœ“ Model loading
- âœ“ Point cloud processing

### Test Converter Setup

```bash
python test_converter_setup.py
```

Verifies:
- âœ“ Module imports
- âœ“ Example models
- âœ“ Single file conversion
- âœ“ Batch conversion
- âœ“ Gradio UI integration
- âœ“ Documentation completeness
- âœ“ Converted files present

---

## ğŸ“ Project Structure

```
Find3D/
â”œâ”€â”€ gradio_app.py                    # Web interface [NEW]
â”œâ”€â”€ convert_3d_to_pcd.py            # 3D to PCD converter [NEW]
â”œâ”€â”€ generate_example_models.py       # Test shape generator [NEW]
â”œâ”€â”€ test_gradio_setup.py            # Verification script [UPDATED]
â”œâ”€â”€ test_converter_setup.py          # Converter verification [NEW]
â”‚
â”œâ”€â”€ model/                           # Find3D model code
â”‚   â”œâ”€â”€ backbone/
â”‚   â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ benchmark/              # Benchmark evaluation
â”‚   â”‚   â”œâ”€â”€ demo/                   # Demo visualization
â”‚   â”‚   â””â”€â”€ core.py
â”‚   â”œâ”€â”€ training/
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ dataengine/                      # Data generation pipeline
â”‚   â”œâ”€â”€ data_process/
â”‚   â”œâ”€â”€ label3d/
â”‚   â”œâ”€â”€ llm/
â”‚   â”œâ”€â”€ rendering/
â”‚   â”œâ”€â”€ seg2d/
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ common/                          # Shared utilities
â”‚
â”œâ”€â”€ example_models/                  # Test 3D shapes [NEW]
â”‚   â”œâ”€â”€ cube.obj
â”‚   â”œâ”€â”€ sphere.obj
â”‚   â”œâ”€â”€ pyramid.obj
â”‚   â””â”€â”€ torus.obj
â”‚
â”œâ”€â”€ converted/                       # Pre-converted point clouds [NEW]
â”‚   â”œâ”€â”€ *_pointcloud.pcd
â”‚
â””â”€â”€ Documentation (8 files) [NEW]
    â”œâ”€â”€ 3D_CONVERTER_GUIDE.md
    â”œâ”€â”€ CONVERTER_QUICKSTART.md
    â”œâ”€â”€ CONVERTER_IMPLEMENTATION.md
    â”œâ”€â”€ GRADIO_GUIDE.md
    â”œâ”€â”€ GRADIO_INTERFACE.md
    â”œâ”€â”€ INSTALLATION.md
    â”œâ”€â”€ SETUP_COMPLETE.md
    â””â”€â”€ TORCH_UPDATE.md
```

---

## ğŸ“š Documentation Files

### New Documentation

- **3D_CONVERTER_GUIDE.md** - Complete converter reference with examples
- **CONVERTER_QUICKSTART.md** - Quick-start workflows and examples
- **CONVERTER_IMPLEMENTATION.md** - Feature summary and implementation details
- **GRADIO_GUIDE.md** - Gradio interface guide
- **GRADIO_INTERFACE.md** - Detailed interface documentation
- **INSTALLATION.md** - Complete installation instructions
- **SETUP_COMPLETE.md** - Setup verification
- **TORCH_UPDATE.md** - PyTorch 2.10 upgrade details

### Original Documentation

See: [`dataengine/README.md`](dataengine/README.md), [`model/evaluation/benchmark/README.md`](model/evaluation/benchmark/README.md)

---

## ğŸ” Common Workflows

### Workflow 1: Quick Test with Examples

```bash
# 1. Launch interface
python gradio_app.py

# 2. Converter tab:
#    - Upload example_models/cube.obj
#    - Click Convert
#    - Download cube_pointcloud.pcd

# 3. Inference tab:
#    - Upload the downloaded file
#    - Query: "top face, bottom face"
#    - Click Run Inference
```

### Workflow 2: Convert Your Own Models

```bash
# 1. Place models in a directory
mkdir my_models
cp /path/to/*.obj my_models/
cp /path/to/*.glb my_models/

# 2. Batch convert
python convert_3d_to_pcd.py --batch my_models/ --output ./pcds/

# 3. Launch interface
python gradio_app.py

# 4. Upload and test each .pcd file
```

### Workflow 3: Programmatic Processing

```python
from convert_3d_to_pcd import convert_3d_to_pcd
from model.evaluation.utils import load_model, preprocess_pcd

# Convert
pcd_path = convert_3d_to_pcd("model.glb", num_points=20000)

# Load Find3D
model = load_model()

# Inference
xyz, rgb, normal = read_pcd(pcd_path)
xyz_full, xyz_sub = preprocess_pcd(xyz, normal)

with torch.no_grad():
    logits = model(xyz_sub, text_embeds)
    predictions = logits.argmax(dim=1)
```

### Workflow 4: Benchmark Evaluation

```bash
# 1. Download benchmarks
#    See model/evaluation/benchmark/README.md

# 2. Run evaluation
cd model
python evaluation/benchmark/eval_benchmark.py \
  --benchmark ShapeNetPart \
  --data_root /path/to/data

# 3. Check results
```

---

## âš¡ Performance Tips

### Point Count Trade-offs

| Points | Quality | Speed | Memory | Typical Use |
|--------|---------|-------|--------|------------|
| 5,000 | Low | âš¡âš¡âš¡ Fast | Tiny | Testing |
| **10,000** | **Normal** | **âš¡âš¡ Fast** | **Small** | **Default** |
| 20,000 | High | âš¡ Moderate | Medium | Detailed |
| 50,000+ | Very High | Slow | Large | Research |

**Recommendation**: Start with 10,000-15,000 points for best balance.

### Speed Optimization

```bash
# Use random sampling (faster but less uniform)
python convert_3d_to_pcd.py model.obj -m random -n 5000

# Skip normalization if not needed
python convert_3d_to_pcd.py model.obj --no-normalize

# Reduce batch size if out of memory
# (In Gradio, reduce sample points slider)
```

---

## ğŸ› Troubleshooting

### Converter Issues

**"Could not load mesh"**
- Verify file format is supported (.obj, .glb, .ply, .stl, .off, .gltf, .fbx)
- Try opening in Blender or MeshLab to verify file validity
- Check file permissions

**"File not found"**
- Verify file path is correct
- Use absolute paths if unsure
- Check for typos in filename

**"Slow conversion"**
- Reduce `-n` points parameter
- Use `--method random` instead of poisson
- Consider simplifying mesh geometry

### Gradio Interface Issues

**"Module not found"**
- Ensure you're using the correct Python environment:
  - `source .venv/bin/activate` (if using venv)
  - `conda activate find3d` (if using conda)
- Verify all requirements installed: `pip list | grep -E "gradio|torch|open3d"`

**"CUDA out of memory"**
- Reduce number of sample points
- Reduce batch size
- Close other applications
- Use CPU (slower): Set `device = torch.device("cpu")`

**"Model loading failed"**
- Check CUDA availability: `nvidia-smi`
- Verify Python environment
- Run verification: `python test_gradio_setup.py`

### Inference Issues

**"No points segmented"**
- Verify point cloud uploaded correctly
- Try different temperature setting
- Use more specific part names
- Check point count (too few = missed parts)

**"Wrong segmentation"**
- Adjust temperature (lower = sharper)
- Use more descriptive queries
- Try heatmap mode to debug confidence
- Verify point cloud orientation

---

## ğŸ“ˆ Benchmarks & Results

Find3D was evaluated on:
- ShapeNetPart
- PartNetE
- Objaverse-ShapeNetPart (unseen category)

Results exceed prior work on open-world part segmentation.

See paper for detailed comparisons: https://arxiv.org/abs/2411.13550

---

## Citing <a name="citing"></a>

Original Find3D work:

```bibtex
@misc{ma20243d,
      title={Find Any Part in 3D}, 
      author={Ziqi Ma and Yisong Yue and Georgia Gkioxari},
      year={2024},
      eprint={2411.13550},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2411.13550}, 
}
```

---

## ğŸ”— Links

- **Project Site**: https://ziqi-ma.github.io/find3dsite/
- **Paper**: https://arxiv.org/abs/2411.13550
- **Demo**: https://huggingface.co/spaces/ziqima/Find3D
- **Original Code**: https://github.com/ziqi-ma/Find3D
- **This Fork**: https://github.com/maepopi/Find3D

---

## ğŸ“ License

See LICENSE file for original Find3D license.

Enhancements by Claude AI are provided as-is.

---

## Authors

**Original Find3D:**
- [Ziqi Ma](https://ziqi-ma.github.io/) - State Key Lab of CAD&CG, Zhejiang University
- [Yisong Yue](http://www.yisongyue.com/) - Caltech
- [Georgia Gkioxari](https://gkioxari.github.io/) - Meta AI

**Enhancements (this fork):**
- Claude AI with GitHub Copilot

---

[zm]: https://ziqi-ma.github.io/
[yy]: http://www.yisongyue.com/
[gg]: https://gkioxari.github.io/
